% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% F6, F11, F6, F6, F7 to compile.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}
\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf EMSS: Entity Matching in a Semi-Supervised way}




%for single author (just remove % characters)
\author{
{\rm Jia R. Wu}\\
University of Waterloo
\and
{\rm Shaokai Wang}\\
University of Waterloo
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
\thispagestyle{empty}


\subsection*{Abstract}



\section{Introduction}
Entity matching (EM), also known as Entity Resolution (ER), in the world of data management refers to resolving duplicate entities to a single entity. Matching may be done in a probabilistic or a deterministic (rule-based) manner.  Magellan is an end-to-end entity matching framework that utilizes machine learning to perform both manners of entity matching. Active learning in the context of machine learning describes the process of a user actively providing labels for model training. This paradigm of active human labeling is referred to as human-in-the-loop machine learning. In this following paper we are interested in applying active learning techniques to machine learning for Entity Matching. 

We provide a comparison of Entity Matching across popular systems such as Magellan and Dedupe.io \cite{bilenko2004learnable}. Comparisons are conducted with two datasets BUY and RESTAURANT (add names for these later). Additionally, we provide a fully reproducible and containerized environment for execution requiring no external dependencies other than Docker \cite{docker:2014}. Finally, we extend Magellan with semi-supervised learning and demonstrate that comparable accuracy for EM can be achieved with less samples. 
\\

We make the following contributions:
\begin{itemize}
  \item An evaluation of EM across common systems
  \item A framework for reproducible execution
  \item An active-learning extension for EM (semi-supervised)
\end{itemize}



\section{Related Work}
Perhaps don't need subsections here. A list may be sufficient.

Talk about dedupe primarily since it is what is being utilized

There has been much work done throughout the years to address entity matching. Efforts ranging from traditional machine learning solutions such as 
Talk about structured and unstructured EM

In this work, we focus on structured entity matching when resolving two csv tables.

\subsection{Magellan}
Magellan is described as an end-to-end EM framework as it provides the user with a toolset to conduct EM from the beginning of the workflow through the end. These tools include user guides, strategies for blocking, sampling and matching. The following is a description of the Magellan workflow.

Initially, Magellan computes the cartesian product of both tables. From this resultant set of ordered pairs, an overlap blocker is applied for a resulting set C. The blocking technique used within Magellan is an overlap blocking one. Attributes are tokenized into q-grams and blocked together if they share 1 minimum overlap bewteen q-grams. Subsequently, a sample denoted by S of 450 tuples is taken from this ordered set C. Users are expected to add labels to these, denoting if they are identical entities or not. 

I and J are computed from this labeled set S.

I is training set. J is testing set.

Feature vectors are then extracted from tables I and J. An example of a feature in this instance would be a function that maps a tuple pair into a value. If the attributes are textual, a feature could be a 3-gram jaccard score. Sample set S is thus split into training and testings sets, and six various machine learning strategies are applied to match values. The six included are Decision Tree, Support Vector Machine, Random Forest, Logistic Regression, Linear Regression and Naive Bayes. Each matcher is evaluated on the test set J and the test set I for precision and recall. 

(verify if true) In theory, the matcher can then be applied to the entire dataset. 





\subsection{Dedupe.io}
Discuss why they have no publication
Dedupe.io is available as both an open source and as a paid service for EM. We will focus on the open source implementation implementation of dedupe in this paper. 

The workflow of Dedupe.io is 

The bread and butter of Dedupe.io consists of 3 parts, a learnable matching function, an active labeling component and a clustering component. 




\section{Methods}
Have a section on why the DBLP-ACM benchmark was used.
Have a section on why we used Docker.
Describe what was done to extend. (Active learning part)


\section{Results}
Describe the performance of using ActiveLearning in Magellan.


\noindent\fbox{
    \parbox{\columnwidth}{
    	\centering
        \textit{Add Key Magellan Result/Conclusion Here}
    }
}
\\\\

\section{Challenges}
Describe the ease of use of each system here.
Describe the potential performance of each system here.

Initially the challenge was determining why Magellan had not attempted to build 








\section{Threats To Validity}


\section{Future Work}


\section{Acknowledgments}


\section{Availability}\label{Availability}
All relevant scripts and data can be retireved from the following repository:
\begin{center}
{\tt https://github.com/JRWu/cs848w20}
\end{center}

{\footnotesize \bibliographystyle{acm}

\theendnotes

\newpage
\bibliography{bibliography}}

\end{document}

